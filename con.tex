\documentclass[17pt]{article}
\usepackage[russian]{babel}
\usepackage{graphicx}
\usepackage{framed}
\usepackage{listings}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    allcolors=blue
}
\lstset{numbers=left}
\usepackage{amsthm, amsmath, amssymb}
\usepackage{tikz}
\usepackage[margin=2cm]{geometry}

\title{Многоядерные структуры и поиск}
\author{Первунецких Еремей}
\date{\today}

\begin{document}
\maketitle

Целью данного мероприятия является возможность заинтересовать людей в изучении многоядерных структур данных. Я постарался собрать всё, что мне было бы нужно услышать в первую очередь, прежде чем писать свои первые проекты, а также добавил немного того, что выходит за рамки обычного курса многопоточного программирования и затрагивает недавние идеи, созданные в этой области.

\section*{Итоговая задача}
В конечном итоге мы хотели бы написать \textsc{wait-free} сбалансированное дерево, которое будет способно быстро обрабатывать запросы, не ломаться в случаях аварийных завершений и разумно работать с оперативной памятью.

\section*{\large{Лекция первая}}
\section{Многопоточное исполнение}

\emph{Процессом исполнения} называется последовательный запуск инструкций, который в любой момент может быть прерван планировщиком системы и возобновлён через некоторое время. За данный промежуток состояние системы может кардинально измениться в пределах используемых функций. Единственным способом сделать какое-либо действие \emph{атомарно} - использовать специальные инструкции процессора, которые в большинстве языков программирования сведены в отдельный тип и называются \emph{atomic}.

Так или иначе ядро ОС предоставляет системные вызовы, которые предоставляют \emph{блокирующий} механизм синхронизации - \emph{mutex}. Он универсален и достаточно быстр и оптимален, если речь идёт об использовании других системных вызовов в этом же блоке кода. Но если заглянуть глубже в те механизмы, которые мы используем для обработки запросов, то оказывается, что его скорости мягко говоря недостаточно. В зависимости от того, какие механизмы синхронизации мы используем, появляется 4 основных вида гарантий работы приложения:

\begin{itemize}
	\item Блокирующие
	\begin{itemize}
		\item \textsc{locked} - мы верим, что программа завершится когда-нибудь, но мы не можем гарантировать, что система будет выполнять какие-либо действия, если каким-либо потокам будет дано управление
		\begin{lstlisting}[language=C++]
int memory = 0;
std::mutex lock_mutex;
int fetch_add() {
	std::lock_guard<std::mutex> lock(lock_mutex); // mutex.lock();
	int cur_memory = memory++;
	// ~lock_guard<std::mutex>(lock)              // mutex.unlock();
	return cur_memory;
}
		\end{lstlisting}
	
	\end{itemize}
	\item Неблокирующие
	\begin{itemize}
		\item \textsc{obstruction-free} - мы гарантируем, что система будет продвигаться, если на пути одного потока не будет встречено никаких других. Иначе гарантии нет
		\begin{lstlisting}[language=C++]
int memory = 0;
std::atomic<bool> spin_lock{false};
int fetch_add() {
    bool expected = false;
    while (spin_lock.compare_exchange_weak(expected, true))
		std::this_thread::yield();
    int cur_memory = memory++;
    spin_lock.store(false);
    return cur_memory;
}
		\end{lstlisting}
		Данный пример НЕ является \textsc{obstruction-free}, потому что система не будет продвигаться в случае выключения потоков в процессе работы. \textsc{obstruction-free} являются методы, которые, например, сначала используют несколько CAS, и в случае отказа хотя бы одного выполняют операцию снова. Такая гарантия нужна, чтобы показать что процесс \textsc{lock-free} только в специфичных случаях.
	

		\item \textsc{lock-free} - мы гарантируем, что в целом система будет продвигаться в каждый момент времени, но нет гарантии, что та или иная операция будет завершена за конечное число шагов
		\begin{lstlisting}[language=C++]
std::atomic<int> memory{0};
int fetch_add() {
	int cur_memory = memory.load();
	while (!memory.compare_exchange_weak(cur_memory, cur_memory + 1)) {
		cur_memory = memory.load();
	}
	return cur_memory;
}
		\end{lstlisting}

		\item \textsc{wait-free} - самая сильная гарантия, мы уверены в том, что каждая операция будет завершена за конечное число шагов
		\begin{lstlisting}[language=C++]
std::atomic<int> memory{0};
int fetch_add() {
	return memory.fetch_add(1);
}
		\end{lstlisting}
	
	\end{itemize}
\end{itemize}

В дальнейшем мы будем прибегать в общим приемам, которые эти гарантии предоставляют.

\vfill
\section{Особенности работы с памятью}

У каждого потока есть своя локальная память, которую он может менять без опасений изменения другими потоками. Также у него есть доступ к общей памяти. Чтобы понять какие проблемы могут возникнуть при её изменении давайте представим следующие программы:

\begin{minipage}{0.5\textwidth}
\begin{lstlisting}[language=C++]
Object *ref;
void first() {
	ref = new Object(A);
	// the thread has stopped
	if (ref != nullptr) {
		// do smth with A
	}
}
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{0.5\textwidth}
\begin{lstlisting}[language=C++]
void second() {
	if (ref != nullptr) delete ref;
	ref = new Object(B);
}
\end{lstlisting}
\end{minipage}

Решением подобного рода проблем, связанных с удалением данных, является применение SMR(safe memory reclamation) алгоритмов (либо сборщика мусора для некоторых языков). Суть их очень проста - они сначала дожидаются завершения всех потоков, имеющих ссылку на удаляемый объект, и лишь затем осуществляют освобождение. Мы рассмотрим два из них, для начала поговорим о счётчике ссылок.

\vfill
\section{Счётчик ссылок}

Первое решение, приходящее в голову - аккуратно подсчитывать количество ссылающихся на объект потоков, чтобы при достижении нуля начать освобождение. Давайте реализуем \textsc{mutex-based} подход

\begin{lstlisting}[language=C++]
using ull = unsigned long long;
class ReferenceCounter {
	ull counter = 1;
	std::mutex lock_mutex;
public:
	bool increment() {
		std::lock_guard<std::mutex> lock(lock_mutex);
		if (counter != 0) {
			++counter;
			return true;
		}
		return false;
	}
	bool decrement() {
		std::lock_guard<std::mutex> lock(lock_mutex);
		if (counter == 0) return false;
		if ((--counter) == 0) {
			return true;
		}
		return false;
	}
	ull get_counter() {
		std::lock_guard<std::mutex> lock(lock_mutex);
		return counter;
	}
};
\end{lstlisting}

Давайте его немного ускорим и превратим в \textsc{lock-free}

\begin{lstlisting}[language=c++]
using ull = unsigned long long;
class ReferenceCounter {
	std::atomic<ull> counter = 1;
public:
	bool increment() {
		ull cur_counter = counter.load();
		while (cur_counter != 0 &&
		!counter.compare_exchange_weak(cur_counter, cur_counter + 1)) {
			cur_counter = counter.load();
		}
		return cur_counter != 0;
	}
	bool decrement() {
		return counter.fetch_sub(1) == 1;
	}
	ull get_counter() {
		return counter.load();
	}
};
\end{lstlisting}

\vfill
Заметим, что наше состояние всегда определено и на написание каждой операции мы не меняем функции. Но что здесь

\begin{lstlisting}[language=c++]
using ull = unsigned long long;
class ReferenceCounter {
	std::atomic<ull> counter = 1;
	const ull zero_flag = (1ll << 63);
public:
	bool increment() {
		return ((counter.fetch_add(1) & zero_flag) == 0);
	}
	bool decrement() {
		if (counter.fetch_sub(1) == 1) {
			ull expected = 0;
			if (counter.compare_exchange_strong(expected, zero_flag)) {
				return true;
			}
		}
		return false;
	}
	ull get_counter() { // weak - the cake is a lie
		ull cur_counter = counter.load();
		if (cur_counter & zero_flag) return 0;
		if (cur_counter == 0) return 1;
		return cur_counter;
		// we will change this function to explain help approach
	}
};
\end{lstlisting}

Мы можем представить, что операция \emph{increment} будет вызвана после \emph{fetch\_sub(1)}, но до \emph{compare\_exchange}. Тогда состояние счетчика будет 0 и операция прибавления 1, будучи реально вызванной после \emph{decrement}, изменит состоянее до неё, то есть по сути будет исполнена раньше. Нам необходимо будет определить что вообще значит порядок операций в терминах параллельного программирования, но для начала поговорим о простейшем применении данного счётчика.

\vfill
\subsection{Механизм COW для строк}

Допустим мы хотим научиться сжимать создаваемую при копировании строк информацию, чего с помощью COW делать не стоит (более того его из-за некоторых причин удалили для строк в 11-ом стандарте C++). Тогда вместо обычного \emph{basic\_string} вида

\begin{lstlisting}[language=c++]
class basic_string {
	size_t size;
	char  *c_str;
public:
	basic_string(const basic_string &other) {
		size = other.size;
		c_str = new char[size];
		memcpy(c_str, other.c_str, size);
	}
};
\end{lstlisting}

Будем при копировании лишь ссылаться на тот же \emph{c\_str}, не переписывая заново его содержимое. Если при изменении мы являемся исключительным владельцем данной строки, то тогда мы действительно поменяем данные. Иначе мы скопируем строку, как мы и хотели до этого.

\begin{lstlisting}[language=c++]
class basic_string {
	size_t size;
	char  *c_str;
	ReferenceCounter *counter;
public:
	basic_string(const basic_string &other) {
		if (!other.counter->increment())
			throw std::invalid_argument("");
		size = other.size;
		c_str = other.c_str;
		counter = other.counter;
	}
	char& operator[](size_t index) {
		if (counter->get_counter() > 1) {
			char *new_c_str = new char[size];
			memcpy(new_c_str, c_str, size);
			if (counter->decrement()) {
				delete c_str;
			}
			c_str = new_c_str;
			counter = new ReferenceCounter();
		}
		return c_str[index];
	}
	~basic_string() {
		if (counter->decrement()) {
			delete c_str;
			delete counter;
		}
	}
};
\end{lstlisting}

\vfill
\subsection{Help подход и взаимопомощь}

Чтобы добавить метод \emph{get\_counter} в \emph{ReferenceCounter} без трюков с переупорядочиванием давайте разберёмся с механизмом помощи. Пусть тот поток, который получил значение счётчика 1 при вызове \emph{get\_counter} поможет установить его в \emph{zero\_flag} и даст понять это потоку с вызванным \emph{decrement}. В исходном материале, откуда было это всё взято есть дополнительная проверка на то, что только один поток из \emph{decrement} смог бы поменять счётчик из состояния когда уже помогли и он ровно \emph{zero\_flag}. Эта проверка - \emph{counter.exchange(zero\_flag)} \& \emph{help\_flag}. Она не необходима, но её труднее убрать чем добавить.

\begin{lstlisting}[language=c++]
using ull = unsigned long long;
class ReferenceCounter {
	std::atomic<ull> counter = 1;
	const ull zero_flag = (1ll << 63);
	const ull help_flag = (1ll << 62);
public:
	bool increment() {
		return ((counter.fetch_add(1) & zero_flag) == 0);
	}
	bool decrement() {
		if (counter.fetch_sub(1) == 1) {
			ull expected = 0;
			if (counter.compare_exchange_strong(expected, zero_flag)) {
				return true;
			} else if ((expected & help_flag) &&
			(counter.exchange(zero_flag) & help_flag)) {
				return true;
			}
		}
		return false;
	}
	ull get_counter() { // strong - the cake is real
		ull cur_counter = counter.load();
		if (cur_counter == 0 &&
		counter.compare_exchange_strong(cur_counter, zero_flag | help_flag)) {
			return 0;
		}
		if (cur_counter & zero_flag) {
			return 0;
		}
		return cur_counter;
	}
};
\end{lstlisting}

Заметьте как получается использовать время другого потока, потраченное на помощь, чтобы развернуть бесконечный цикл в конечное исполнение на всей системе. Мы будем рассматривать это дальше в \textsc{lock-free} очереди Майкла и Скотта, которая использует эту технику для поддержания одного полезного свойства системы. Помимо прочего такой подход в принципе нужен по причине стабильности документации. Даже если мы будем аккуратно врать, то трудоемкость поддержки последней резко возрастает, нежели чем работать с ситуацией, где соблюдается инвариант структуры.

\vfill
\section{Линеаризуемость}

Вернёмся к проблеме, возникшей при написании \textsc{wait-free} счётчика, связанной с \emph{get\_counter}. Давайте рассмотрим один из вариантов исполнения функции.

\begin{tikzpicture}[scale=0.8]
	\draw[->] (0,0) -- (10,0);
	\draw[blue!80] (0.0, 0.5) rectangle (8.0, 1.0) node[midway] {decrease};
	\draw[blue!100, ultra thick, -] (1.0, -0.5) -- (1.0, 1.0) node[pos = -0.5, above] {fetch\_sub(1) == 1};
	\draw[blue!100, ultra thick, -] (7.8, -0.5) -- (7.8, 1.0) node[pos = -0.5, above] {CAS!};
	\draw[red!80] (3.0, 0.0) rectangle (9.5, 0.5) node[midway] {get\_counter};
	\draw[red!100, ultra thick, -] (4.5, -0.5) -- (4.5, 0.5) node[pos = -0.5, above] {load() == 0};
	\draw[red!100, ultra thick, -] (9.2, -0.5) -- (9.2, 0.5) node[pos = -0.5, above] {return 1};
\end{tikzpicture}

Объект называется \emph{линеаризуемым}, если любая операция над ним выполняется \emph{атомарно} в какой-то момент времени. И более того, любое чтение возвращает результат всех выполненных на момент его прихода записей. То есть нашу операцию можно воспринимать как \emph{атомарную}, а всю систему - как набор последовательных инструкций, и именно это и позволяет нам писать идущие друг за другом операции в \emph{линеаризуемой} системе, использующей эти \emph{линеаризуемые} объекты. Все примеры счетчиков являеются линеаризуемыми, поскольку мы можем \emph{оправдать} их поведение соотвествующим атомарным, так чтобы результат остался корректным. Является ли предыдущая реализация COW строк линеаризуемой? Почему?

Если бы наша согласованность операций была бы \emph{последовательная}, чему есть термин \emph{Sequential consistency}, то судя по ней "результат любого выполнения такой же, как в случае если бы \textbf{операции всех процессоров были выполнены в некотором последовательном порядке}, и операции каждого отдельного процессора появлялись в этой последовательности в порядке определённом его программой" (то есть в том самом порядке, какой дан из определения процесса). Является ли реализация COW строк последовательно согласованной? Почему?

\vfill
\section{RCU как несимметричный механизм SMR}

Чтобы научиться выполнять операцию записи в многопоточную структуру данных необходимо учесть то, что в текущий момент есть потоки, которые выполняют оттуда чтение. Одним из решений, в основном применимых в \emph{kernel-space} (но также существующих в \emph{user-space}) является RCU. Мы будем менять данные атомарно, затем дожидаться завершения всех читающих потоков, и только после этого изменять их. То есть при работе с ссылками каждый читающий поток входит в критическую секцию и запрещает прерывать себя. А пишущий поток пытается исполнить себя на каждом ядре, таким образом у него это выйдет только после того, как данные безопасно обработаются и не будут доступны.

\begin{tikzpicture}[scale=0.8]
	\draw[->] (0,0) -- (10,0);
	\draw[green!80] (1.0, 0.5) rectangle (3.0, 1.0) node[midway] {reader};
	\draw[red!80] (3.0, 0.5) rectangle (8.0, 1.0) node[midway] {reader};
	\draw[red!80] (2.0, 1.0) rectangle (5.0, 1.5) node[midway] {reader};
	\draw[green!80] (5.0, 1.0) rectangle (7.0, 1.5) node[midway] {reader};
	\draw[blue!80] (4.0, 0.0) rectangle (7.0, 0.5) node[midway] {writer};
	\draw[blue!100, ultra thick, -] (4.5, -0.5) -- (4.5, 1.5) node[pos = -0.4, above] {CAS!};
	\draw[orange!80] (7.0, 0.0) rectangle (9.0, 0.5) node[midway] {waiting};
	\draw[orange!100, ultra thick, -] (8.0, -0.5) -- (8.0, 1.0) node[pos = -0.5, above] {deleted};
\end{tikzpicture}

Заметим также, что просто входить в критическую секцию для обеспечения \textsc{wait-free} подхода возможно только если система работает на одном ядре, в нашем же случае мы лишь используем этот механизм для бесплатного отслеживания состояния потоков. Также запись будет не то чтобы \textsc{lock-free}, скорее всего проще будет реализовать \textsc{locked} алгоритм, зато чтение будет \textsc{wait-free} и практически не требовать ничего для его реализации.

\vfill
\section{Lock-free очередь майкла-скотта}

Представим себе задачу - нам необходимо написать \textsc{lock-free} очередь, так что у нас есть \emph{head} и \emph{tail} - ссылки на голову и хвост, соответсвенно. Изначально в ней лежит одна пустая вершина, при взятии которой с головы мы будем делать стоящую после неё вершину такой же пустой. Надо придумать инвариант, который потоки будут сохрянять при работе с этой очередью, который сильно поможет в результате.

Пусть конец очереди никогда не будет отставать от настоящего конца более чем на 1 элемент. Если мы можем помочь сдвинуть \emph{tail} на следующий за ним, то мы \emph{сделаем} это. То есть мы для \emph{enqueue} в бесконечном цикле сначала будем менять конец на следующий после него элемент, и если такого нет, то поменяем его на наш, добавляемый. Аналогично для \emph{dequeue}, поскольку очередь может находится в состоянии \emph{head == tail} и мы не сможем забрать элемент. Затем мы просто меняем голову очереди и используем наш вынутый элемент. Чтобы его удалить нам понадобится какой-либо механизм SMR, но суть от этого не меняется.

\vfill
\section*{\large{Лекция вторая}}
\section{Односвязный список как последовательная структура данных}

Для того, чтобы решить итоговую задачу нужно сначала научиться поддерживать структуру данных, в которой может происходить 3 операции: поиск элемента, вставка элемента в определенное место, удаление элемента. Давайте хранить односвязный список, состоящий из вершин с полями \emph{T data} и \emph{Node *next}. Поиск будет происходить итерационно, вставка и удаление будут содержать в себе предварительный поиск, и в случае успеха, требуемую операцию.

\begin{enumerate}
	\item Coarse-grained - обычным образом написанная структура, мы будем блокировать весь список, производить нашу операцию и затем разблокировать всё. В реализации можно заметить тип \emph{recursive\_mutex}, который, как и обычный \emph{mutex}, работает за счёт средств ядра ОС, вызывая системный вызов на блокировку. Примечателен он тем, что при повторном запросе от того же потока блокировку он не вызывает.
	\item Fine-grained - давайте идти повершинно, блокируя их только при входе и разблокируя при выходе. Так мы можем позволить немного разделить обход, но такое поведение не сильно улучшает ситуацию, поскольку мы всё ещё используем системные вызовы. Также заметим что у нас не может произойти никакого плохого случая, даже при том, что мы всё-таки используем параллельную обработку списка в нескольких местах одновременно.
	\item Optimistic syncronization - позволим себе сначала пройтись до вершины, и только затем заблокировать её. Если мы не смогли её снова найти, то есть её кто-то удалил, то повторим весь проход. И это релевантно только для удаления, поскольку вставка осуществляется сразу после элемента.
	\item Lazy syncronization - не будем заново всё обходить, попробуем просто хранить флаг логической удаленности вершины. Мы будем его игнорировать при проходе, поскольку с ним ничего уже не сделать. При вставке после блокировки уже никто не сможет изменить его, поэтому его состояние актуально. При удалении аналогичная ситуация, только в случае удаленности предыдущей вершины необходимо заново её найти.
	\item Non-blocking syncronization - попробуем использовать тот факт, что количество действий реальной обработки при удалении/добавлении мало. Будем использовать CAS, который работает только с 64-битными ссылками: заменим первый бит указателя на следующий элемент на логическую удаленность текущего. Мы сначала терпим небольшую неудачу при применении физического удаления после логического. Но, если сделать поиск больше не \textsc{wait-free}, а \textsc{lock-free}, добавив в него удаление логически вычеркнутых вершин, то алгоритм получается реализовать. Также можно заметить, что нельзя игнорировать удаленные вершины в этом случае, поскольку иначе они могут быть никогда не удалены.
\end{enumerate}

И мы в итоге получаем наш \textsc{lock-free} односвязный список. Причем наша структура всегда линеаризуема, поскольку каждая операция выполняется за ровно одну инструкцию. Заметим также, что с помощью такого подхода можно реализовать и skip-list, позволяющий хранить данные точно также, но реализующий возможность быстрого поиска с асимптотикой \emph{$O(log(N))$}.

В такой структуре данных к каждому элементу добавляется сверху случайное (и грамотно подобранное) количество ссылок быстрого доступа, которые должны быть связаны между своим уровнем также, как и нижние. То есть ссылки от всех уровней первого элемента(который имеет наибольшую высоту) должны вести последовательно по списку в том же порядке до всех элементов того же уровня, причем если уровень выше, то и количество связей там меньше. Тогда для добавления элемента мы будем поочередно снизу вверх добавлять ссылки. Нижний слой skip-list'а закрепляет элементы и дает гарантию на их существование и порядок, все верхние слои служат лишь для ускоренного поиска. Удаление работает аналогичным образом - мы пытаемся сначала пометить все элементы сверху вниз, и только потом приступаем к физическому удалению в том же направлении.

\vfill
\subsection{Coarse-grained}
\begin{lstlisting}[language=c++]
template <typename T>
class List;

template <typename T>
class Node {
	T        data;
	Node<T> *next;
	
	friend class List<t>;
public:
	Node(T val) : data(val), next(nullptr) {}
	T get_data() { return data; }
};

template <typename T>
class List {
	Node<T> *head; // = dummy node
	std::recursive_mutex lock_mutex;
public:
	Node<T>* search_anc(T elem) {
		std::lock_guard<std::recursive_mutex> lock(lock_mutex);
		Node<T> *cur = head;
		while (cur->next != nullptr) {
			if (cur->next->T == elem) {
				return cur;
			}
			cur = cur->next;
		}
		return nullptr;
	}
	bool insert(T after, T elem) {
		Node<T> *node = new Node<T>{elem};
		std::lock_guard<std::recursive_mutex> lock(lock_mutex);
		Node<T> *found_anc = this->search_anc(after);
		if (found_anc != nullptr) {
			Node<T> *curr = found_anc->next;
			node->next = curr->next; curr->next = node;
			return true;
		}
		return false;
	}
	bool delete(T elem) {
		std::lock_guard<std::recursive_mutex> lock(lock_mutex);
		Node<T> *found_anc = this->search_anc(elem);
		if (found_anc != nullptr) {
			found_anc->next = found_anc->next->next;
			return true;
		}
		return false;
	}
};
\end{lstlisting}

\vfill
\subsection{Fine-grained}
\begin{lstlisting}[language=c++]
template <typename T>
class Node {
	T        data;
	Node<T> *next;
	std::mutex lock_mutex;
	
	friend class List<t>;
public:
	Node(T val) : data(val), next(nullptr) {}
	T get_data() { return data; }
};

template <typename T>
class List {
	Node<T> *head; // = dummy node
public:
	// after search operation need to unlock Node<T> *result and result->next
	Node<T>* search_anc(T elem) {
		Node<T> *cur = head;
		cur->lock_mutex.lock();
		while (cur->next != nullptr) {
			cur->next->lock_mutex.lock();
			if (cur->next->T == elem) {
				return cur;
			}
			cur->lock_mutex.unlock();
			cur = cur->next;
		}
		cur->lock_mutex.unlock();
		return nullptr;
	}
	bool insert(T after, T elem) {
		Node<T> *node = new Node<T>{elem};
		Node<T> *found_anc = this->search_anc(after);
		if (found_anc != nullptr) {
			Node<T> *curr = found_anc->next;
			node->next = curr->next; curr->next = node;
			found_anc->lock_mutex.unlock(); curr->lock_mutex.unlock();
			return true;
		}
		return false;
	}
	bool delete(T elem) {
		Node<T> *found_anc = this->search_anc(elem);
		if (found_anc != nullptr) {
			found_anc->next = found_anc->next->next;
			found_anc->lock_mutex.unlock(); curr->lock_mutex.unlock();
			return true;
		}
		return false;
	}
};
\end{lstlisting}

\vfill
\subsection{Optimistic synchronization}
\begin{lstlisting}[language=c++]
template <typename T>
class List {
	Node<T> *head; // = dummy node
public:
	pair<Node<T>*, Node<T>*> search_anc(T elem) {
		Node<T> *cur = head;
		Node<T> *next_cur = cur->next;
		while (next_cur != nullptr) {
			if (next_cur->T == elem) {
				return {cur, next_cur};
			}
			cur = next_cur;
			next_cur = next_cur->next;
		}
		return {nullptr, nullptr};
	}
	bool insert(T after, T elem) {
		Node<T> *node = new Node<T>{elem};
		while (true) {
			auto [found_anc, curr] = this->search_anc(after);
			if (found_anc == nullptr) return false;
			
			std::lock_guard<std::mutex> lock_next(curr->lock_mutex);
			if (this->search_anc(after).second != curr) return false;
			
			node->next = curr->next; curr->next = node;
			return true;
		}
		return false;
	}
	bool delete(T elem) {
		while (true) {
			auto [found_anc, curr] = this->search_anc(elem);
			if (found_anc == nullptr) return false;
			
			std::lock_guard<std::mutex> lock(found_anc->lock_mutex);
			std::lock_guard<std::mutex> lock_next(curr->lock_mutex);
			if (found_anc->next != curr) continue;
			if (this->search_anc(elem).first != found_anc) continue;

			found_anc->next = curr->next;
			return true;
		}
		return false;
	}
};
\end{lstlisting}

\vfill
\subsection{Lazy synchronization}
\begin{lstlisting}[language=c++]
template <typename T>
class Node {
	T        data;
	Node<T> *next;
	volatile bool    alive;
};

template <typename T>
class List {
	Node<T> *head; // = dummy node
public:
	pair<Node<T>*, Node<T>*> search_anc(T elem) {
		Node<T> *cur = head;
		Node<T> *next_cur = cur->next;
		while (next_cur != nullptr) {
			if (next_cur->T == elem) {
				return {cur, next_cur};
			}
			cur = next_cur;
			next_cur = next_cur->next;
		}
		return {nullptr, nullptr};
	}
	bool insert(T after, T elem) {
		Node<T> *node = new Node<T>{elem};
		while (true) {
			auto [found_anc, curr] = this->search_anc(after);
			if (found_anc == nullptr) return false;
			
			std::lock_guard<std::mutex> lock_next(curr->lock_mutex);
			if (!curr->alive) return false;
			
			node->next = curr->next; curr->next = node;
			return true;
		}
		return false;
	}
	bool delete(T elem) {
		while (true) {
			auto [found_anc, curr] = this->search_anc(elem);
			if (found_anc == nullptr) return false;
			
			std::lock_guard<std::mutex> lock(found_anc->lock_mutex);
			std::lock_guard<std::mutex> lock_next(curr->lock_mutex);
			if (!curr->alive) return false;
			if (found_anc->next != curr) continue;
			if (!found_anc->alive) continue;

			curr->alive = false; found_anc->next = curr->next;
			return true;
		}
		return false;
	}
};
\end{lstlisting}

\vfill
\subsection{Non-blocking synchronization}
\begin{lstlisting}[language=c++]
// Node<T>.next is atomic<Node<T>*>
const size_t alive_flag = (1ll << 63); // Node<T>.next has an alive_flag
const size_t alive_mask = ~alive_flag; // (ref & alive_mask) to use the pointer

template <typename T>
class List {
	pair<Node<T>*, Node<T>*> search_anc(T elem) {
		Node<T> *cur = head;
		Node<T> *next_cur = cur->next; // like atomic.load()
		while (next_cur != nullptr) {
			while (!(next_cur & alive_flag)) { // helping delete
				Node<T> *expected = next_cur;
				if (!cur->next.compare_exchange_strong
						(expected, next_cur->next)) {
					next_cur = head->next;
					// otherwise haven't even lock-free
					// we need to do full traversal
				}
			}
			if (next_cur->T == elem) { // like using alive_mask
				return {cur, next_cur};
			}
			cur = next_cur;
			next_cur = next_cur->next; // like using alive_mask
		}
		return {nullptr, nullptr};
	}
	bool insert(T after, T elem) {
		Node<T> *node = new Node<T>{elem};
		while (true) {
			auto [found_anc, curr] = this->search_anc(after);
			if (found_anc == nullptr) return false;
			Node<T> *expected = curr->next.load(); //preparing for CAS
			if (!(expected & alive_flag)) return false;
			node->next.store(expected);
			if (!curr->next.compare_exchange_weak(expected, node)) continue;
			return true;
		}
		return false;
	}
	bool delete(T elem) {
		while (true) {
			auto [found_anc, curr] = this->search_anc(elem);
			if (found_anc == nullptr) return false;
			Node<T> *expected = curr->next.load(); //preparing for CAS
			if (!(expected & alive_flag)) return false;
			if (!curr->next.compare_exchange_weak
					(expected, expected & alive_flag)) continue;
			found_anc->next.compare_exchange_strong(curr, expected);
			// if last CAS failed then other threads will help!
			return true;
		}
		return false;
	}
};
\end{lstlisting}

\vfill
\section{Универсальные \textsc{wait-free} конструкции}
\subsection{Грамотная постановка задачи}

Гарантии многопоточного программирования нужны не столько по причине скорости их работы (которая является следствием), сколько по их надежности и способности обеспечивать максимальное использование ресурсов вычислительных устройств. Но в некоторых задачах физически невозможно реализовать параллельное исполнение. То есть если в системе \emph{P} потоков, а время выполнения одной операции \emph{T}, то как ни крути, суммарное время будет \emph{$O(PT)$}. Чем же \emph{lock-free} себя выделяет по сравнению с подходом без гарантий? Тем, что на самом деле при остановке исполнения одного из потоков он может обеспечить работу остальных, и хотя бы один выполнит нужную ему операцию. Давайте попытаемся придумать способ, как сделать именно это - обеспечить возможность каждому из потоков выполняться, несмотря на состояние всех остальных

\begin{framed}
Задача: В системе есть \emph{P} потоков исполнения. Каждому на выполнение своей операции над структурой данных \emph{Rx} требуется \emph{T} времени. Необходимо написать способ распределения задач, чтобы при засыпании/просыпании любого из потоков каждый выполнялся бы за конечное число шагов.
\end{framed}

\vfill
\subsection{Тривиальное решение}

При грамотной постановке задачи сразу приходит решение, хоть и медленное. Оно было описано ещё очень давно Морисом Херлихи, и заключается в следующем: мы пытаемся выполнить старые операции всех остальных потоков, пока у нас это не получится. Если у нас так и не вышло, то значит, что кто-то другой уже сделал это за нас. 

\begin{lstlisting}
Operation announce[P];
Result do_operation(Operation x) {
	x.time = operation_counter->increment();
	announce[this_thread_id] = x;
	while (true) {
		if (announce[i].is_done()) {
			return done;
		}
		announce' = announce.copy();
		Rx' = Rx.copy();
		newRx' = Rx';
		for (int i : {0..P-1}) {
			if (announce[i].time <= x.time) {
				do operation announce[i] on newRx';
				announce'[i].done();
			}
		}
		if (!CAS(Rx, Rx', newRx')) continue;
		for (int i : {0..P-1}) {
			if (announce'[i].is_done()) {
				CAS(announce[i], announce'[i].like_not_done, announce'[i]);
			}
		}
	}
	return done;
}
\end{lstlisting}

Можно заметить что такое решение работает за \emph{$O(P^2T)$} сложность, хоть и является \textsc{wait-free}. Необходимо придумать что-то похожее, но попроще

\vfill
\subsection{Решение с помощью \textsc{lock-free} очереди}

Следующим шагом к созданию алгоритма является применения понятия очереди. Пусть все новые процессы будут заносить анонс своей операции в очередь, и потом любой, кто захочет сможет оттуда взять последнюю. Как только кто-то её выполнит мы удалим этот элемент и будем пытаться выполнить следующую операцию. Так или иначе каждому потоку повезет быть исполненым. 

\vfill
\subsection{Добавление gate}

\vfill
\subsection{Доведение до кондиции}

\vfill
\section{\textsc{wait-free} красно-черное дерево}

\vfill
\section{Литература}

Лекция 1
\begin{enumerate}
	\item The art of Multiprocessor Programming \href{https://www.cs.sfu.ca/~ashriram/Courses/CS431/assets/distrib/AMP.pdf}{https://www.cs.sfu.ca/~ashriram/Courses/CS431/assets/distrib/AMP.pdf}
	\item Курс по параллельному программированию \href{https://youtu.be/fhcyQ2wU7Hk?si=QI1Qx9BlBxH4VPl8}{https://youtu.be/fhcyQ2wU7Hk?si=QI1Qx9BlBxH4VPl8}
	\item Подход COW и его описание \href{https://en.wikipedia.org/wiki/Copy-on-write}{https://en.wikipedia.org/wiki/Copy-on-write}
	\item Документация по типам \emph{atomic} в C++ \href{https://en.cppreference.com/w/cpp/atomic/atomic.html}{https://en.cppreference.com/w/cpp/atomic/atomic.html}
	\item Введение в \textsc{wait-free} программирование \href{https://www.youtube.com/watch?v=kPh8pod0-gk}{https://www.youtube.com/watch?v=kPh8pod0-gk}
\end{enumerate}
Лекция 2
\begin{enumerate}
	\item Статьи Максима Хижинского по \textsc{lock-free} \href{https://habr.com/ru/users/khizmax/articles/}{https://habr.com/ru/users/khizmax/articles/}
	\item Библиотека \emph{libcds} того же автора \href{https://github.com/khizmax/libcds}{https://github.com/khizmax/libcds}
	\item Представление необходимых принципов для структур \href{https://oasis.library.unlv.edu/cgi/viewcontent.cgi?article=3425\&context=thesesdissertations}{https://oasis.library.unlv.edu/cgi/viewcontent.cgi
		?article=3425\&context=thesesdissertations}
	\item Универсальные конструкции \textsc{wait-free} \href{https://scispace.com/pdf/a-universal-construction-for-wait-free-transaction-friendly-38as61nsj3.pdf}{https://scispace.com/pdf/a-universal-construction-for-wait-free-transaction-friendly-38as61nsj3.pdf}
	\item \textsc{wait-free} красно-черное дерево поиска \href{https://link.springer.com/chapter/10.1007/978-3-319-03089-0\_4}{https://link.springer.com/chapter/10.1007/978-3-319-03089-0\_4}
\end{enumerate}

\end{document}
